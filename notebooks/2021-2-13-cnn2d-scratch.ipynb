{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzZIEm_jUOyE"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = []\n",
    "p = '2021-2-11-kick_markers/2021-2-12-kick_markers_markers.csv'\n",
    "with open(p, 'r', newline='\\n') as csvfile:\n",
    "    r = csv.reader(csvfile, delimiter=',')\n",
    "    markers = [np.array(row) for row in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_markers = [int(x[2]) for x in markers[1:]]\n",
    "# print(kick_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = []\n",
    "p = '2021-2-11-kick_markers/2021-2-12-snare_markers_markers.csv'\n",
    "with open(p, 'r', newline='\\n') as csvfile:\n",
    "    r = csv.reader(csvfile, delimiter=',')\n",
    "    markers = [np.array(row) for row in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "snare_markers = [int(x[2]) for x in markers[1:]]\n",
    "# print(snare_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data chopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE = 44100\n",
    "def plotSound(data):\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,4))\n",
    "    plt.plot(data, color='blue')\n",
    "    ax.set_xlim((0, len(data)))\n",
    "    plt.show()\n",
    "    IPython.display.display(IPython.display.Audio(data=data, rate=RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9051983\n"
     ]
    }
   ],
   "source": [
    "p = \"2021-2-11-kick_markers/2021-2-11-kick_markers.wav\"\n",
    "a1, sr = librosa.load(p, sr=RATE)\n",
    "print(len(a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_windows = [(m, a1[m-256:m+512*8]) for m in kick_markers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in kick_windows:\n",
    "#     plotSound(w[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9096083\n"
     ]
    }
   ],
   "source": [
    "p = \"2021-2-11-kick_markers/2021-2-12-snare_markers.wav\"\n",
    "a2, sr = librosa.load(p, sr=RATE)\n",
    "print(len(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "snare_windows = [(m, a2[m-256:m+512*8]) for m in snare_markers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in snare_windows:\n",
    "#     plotSound(w[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since latest_start is earliest+128, the onset will never be at 0, but\n",
    "# always shifted to the right. I'm doing this to encourage the model \n",
    "# to see onsets earlier (when the onset represents later data in the frame)\n",
    "# rather than later, but I'm not sure if it's a good idea or not. \n",
    "# Might want to do latest_start = earliest_start+256\n",
    "\n",
    "length = 512\n",
    "earliest_start = 0\n",
    "latest_start   = earliest_start+128\n",
    "earliest_stop  = earliest_start+length # 0+512=512\n",
    "latest_stop    = earliest_stop+128 # 512+128=640\n",
    "\n",
    "labels = []\n",
    "frames = []\n",
    "markers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for marker, data in kick_windows:\n",
    "    fs = [data[i:i+length] for i in range(earliest_start, latest_start)]\n",
    "    labels.extend(['kick']*len(fs))\n",
    "    frames.extend(fs)\n",
    "    markers.extend([marker]*len(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for marker, data in snare_windows:\n",
    "    fs = [data[i:i+length] for i in range(earliest_start, latest_start)]\n",
    "    labels.extend(['snare']*len(fs))\n",
    "    frames.extend(fs)\n",
    "    markers.extend([marker]*len(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9096083\n"
     ]
    }
   ],
   "source": [
    "p = \"2021-2-11-kick_markers/2021-2-12-snare_markers.wav\"\n",
    "nd, sr = librosa.load(p, sr=RATE)\n",
    "print(len(nd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = []\n",
    "noise_window_end = RATE*30 # 30 is the number of seconds of noise we allow from start of file\n",
    "for _ in range(len(frames) // 2):\n",
    "    start = np.random.randint(noise_window_end-length)\n",
    "    stop = start + length\n",
    "    frame = nd[start:stop]\n",
    "    labels.append('noise')\n",
    "    frames.append(frame)\n",
    "    markers.append(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it might be better to use ALL of the noise and balance this by multiplying the number of positive samples. It might also be better to use the noise from the same file [done here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56064\n"
     ]
    }
   ],
   "source": [
    "data = list(zip(frames, labels, markers))\n",
    "np.random.shuffle(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'snare', 'noise', 'kick'}\n"
     ]
    }
   ],
   "source": [
    "print(set([x[1] for x in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8bMse_qgCnUQ",
    "outputId": "171fa933-d034-4fba-bb2a-fd5790e1efa7"
   },
   "outputs": [],
   "source": [
    "train_data = data[:7*len(data)//10]    \n",
    "X_train = [sample[0] for sample in train_data]\n",
    "Y_train = [sample[1] for sample in train_data]\n",
    "markers_train = [sample[2] for sample in train_data]\n",
    "\n",
    "val_data = data[7*len(data)//10:8*len(data)//10]\n",
    "X_val = [sample[0] for sample in val_data]\n",
    "Y_val = [sample[1] for sample in val_data]\n",
    "markers_val = [sample[2] for sample in val_data]\n",
    "\n",
    "test_data = data[8*len(data)//10:]\n",
    "X_test = [sample[0] for sample in test_data]\n",
    "Y_test = [sample[1] for sample in test_data]\n",
    "markers_test = [sample[2] for sample in test_data]\n",
    "\n",
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "X_val = torch.tensor(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1226 175 350\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "print(len(X_train)//batch_size, len(X_val)//batch_size, len(X_test)//batch_size)\n",
    "labels = ['kick', 'snare', 'noise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(0, len(Y_train)-batch_size, batch_size):\n",
    "    x = X_train[i:i+batch_size]\n",
    "    y = torch.tensor([labels.index(y) for y in Y_train[i:i+batch_size]])\n",
    "    train_data.append((x, y))\n",
    "#     print(x.shape)\n",
    "#     print(Y_train[i:i+batch_size])\n",
    "#     print(y)\n",
    "#     print(\"~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "for i in range(0, len(Y_val)-batch_size, batch_size):\n",
    "    x = X_val[i:i+batch_size]\n",
    "    y = torch.tensor([labels.index(y) for y in Y_val[i:i+batch_size]])\n",
    "    val_data.append((x, y))\n",
    "#     print(x.shape)\n",
    "#     print(Y_val[i:i+batch_size])\n",
    "#     print(y)\n",
    "#     print(\"~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(0, len(Y_test)-batch_size, batch_size):\n",
    "    x = X_test[i:i+batch_size]\n",
    "    y = torch.tensor([labels.index(y) for y in Y_test[i:i+batch_size]])\n",
    "    test_data.append((x, y))\n",
    "#     print(x.shape)\n",
    "#     print(Y_test[i:i+batch_size])\n",
    "#     print(y)\n",
    "#     print(\"~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1226 175 350\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(val_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 32\n",
    "input_size = 512\n",
    "num_classes = 3\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n",
      "torch.Size([32, 17, 65])\n",
      "torch.Size([32, 17, 65])\n",
      "torch.Size([32, 1, 17, 65])\n",
      "torch.Size([32, 6, 15, 63])\n",
      "torch.Size([32, 6, 7, 31])\n",
      "torch.Size([32, 12, 5, 29])\n",
      "torch.Size([32, 12, 2, 14])\n",
      "torch.Size([32, 336])\n",
      "torch.Size([32, 256])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "c1 = nn.Conv2d(1, 6, 3)\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "c2 = nn.Conv2d(6, 12, 3)\n",
    "fc1 = nn.Linear(336, 256)\n",
    "fc2 = nn.Linear(256, 128)\n",
    "fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "x = torch.randn(batch_size, input_size)\n",
    "print(x.shape)\n",
    "x = torch.abs(torch.stft(x, n_fft=32, return_complex=True))\n",
    "print(x.shape)\n",
    "x = torch.where(x.sum() > 0, x / torch.max(x), x)\n",
    "print(x.shape)\n",
    "x = x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "x = c1(x)\n",
    "print(x.shape)\n",
    "x = pool(x)\n",
    "print(x.shape)\n",
    "x = c2(x)\n",
    "print(x.shape)\n",
    "x = pool(x)\n",
    "print(x.shape)\n",
    "x = torch.flatten(x, start_dim=1)\n",
    "print(x.shape)\n",
    "x = fc1(x)\n",
    "print(x.shape)\n",
    "x = fc2(x)\n",
    "print(x.shape)\n",
    "x = fc3(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STFT_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(STFT_CNN, self).__init__()\n",
    "        self.c1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.c2 = nn.Conv2d(6, 12, 3)\n",
    "        self.fc1 = nn.Linear(336, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.abs(torch.stft(x, n_fft=32, return_complex=True))\n",
    "        x = torch.where(x.sum() > 0, x / torch.max(x), x)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.pool(F.relu(self.c1(x)))\n",
    "        x = self.drop(x)\n",
    "        x = self.pool(F.relu(self.c2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_model = STFT_CNN(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n",
      "torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(batch_size, input_size)\n",
    "print(x.shape)\n",
    "print(stft_model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(stft_model.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    print('.', end='')\n",
    "    for batch_idx, (data, targets) in enumerate(train_data):\n",
    "        scores = stft_model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_check_accuracy(data, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        print(f'Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 39061/39232 with accuracy 99.56\n"
     ]
    }
   ],
   "source": [
    "stft_check_accuracy(train_data, stft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 11141/11200 with accuracy 99.47\n"
     ]
    }
   ],
   "source": [
    "stft_check_accuracy(test_data, stft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on other dataset (different microphone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right now I'm using files that are 3072 +/- 1 samples long\n",
    "directory = os.path.join('./dataset/kick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd = {}\n",
    "for file in os.listdir(directory):\n",
    "    if file[-3:] == 'wav':\n",
    "        file_path = os.path.join(directory, file)\n",
    "        d, sr = librosa.load(file_path, sr=RATE)\n",
    "        kd[file] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join('./dataset/snare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = {}\n",
    "for file in os.listdir(directory):\n",
    "    if file[-3:] == 'wav':\n",
    "        file_path = os.path.join(directory, file)\n",
    "        d, sr = librosa.load(file_path, sr=RATE)\n",
    "        sd[file] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17970826\n"
     ]
    }
   ],
   "source": [
    "noise_file = './dataset/noise_all/noise_all.wav'\n",
    "nd, sr = librosa.load(noise_file, sr=RATE)\n",
    "print(len(nd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 512\n",
    "earliest_start = 1000-256\n",
    "latest_start   = earliest_start+128\n",
    "earliest_stop  = earliest_start+length\n",
    "latest_stop    = earliest_stop+128\n",
    "\n",
    "labels = []\n",
    "files = []\n",
    "frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in kd:\n",
    "    data = kd[k]\n",
    "    fs = [data[i:i+length] for i in range(earliest_start, latest_start)]\n",
    "    labels.extend(['kick']*len(fs))\n",
    "    files.extend([k]*len(fs))\n",
    "    frames.extend(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sd:\n",
    "    data = sd[k]\n",
    "    fs = [data[i:i+length] for i in range(earliest_start, latest_start)]\n",
    "    labels.extend(['snare']*len(fs))\n",
    "    files.extend([k]*len(fs))\n",
    "    frames.extend(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = []\n",
    "for _ in range(len(frames) // 2):\n",
    "    start = np.random.randint(len(nd)-length)\n",
    "    stop = start + length\n",
    "    frame = nd[start:stop]\n",
    "    labels.append('noise')\n",
    "    files.append('noise_all.wav')\n",
    "    frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12288\n"
     ]
    }
   ],
   "source": [
    "data = list(zip(frames, labels, files))\n",
    "np.random.shuffle(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'snare', 'noise', 'kick'}\n"
     ]
    }
   ],
   "source": [
    "print(set([x[1] for x in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8bMse_qgCnUQ",
    "outputId": "171fa933-d034-4fba-bb2a-fd5790e1efa7"
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "labels = ['kick', 'snare', 'noise']\n",
    "second_test_data = data   \n",
    "X_second_test = torch.tensor([sample[0] for sample in second_test_data])\n",
    "Y_second_test = torch.tensor([labels.index(sample[1]) for sample in second_test_data])\n",
    "files_second_test = [sample[2] for sample in second_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_model.eval()\n",
    "scores = stft_model(X_second_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12288])\n"
     ]
    }
   ],
   "source": [
    "_, predictions = scores.max(1)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = (predictions == Y_second_test).sum()\n",
    "# num_samples += predictions.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.51399739583334"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(num_correct)/float(predictions.size(0))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(batch_size, input_size)\n",
    "stft_model.eval()\n",
    "traced_script_module = torch.jit.trace(stft_model, x)\n",
    "print(traced_script_module(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"traced_model_cnn_0.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs at what feels like 3.5/5.0. In other words it appears to be trying but clearly needs work. Limiting contiguous repeats helps but the main issue seems to be confusion between kick and snare, especially in the direction of kick being confused for snare. Especially when used with limiting contiguous repeats, it appears that the tail of the kick is confused for a snare. It also seems that the first opportunity frames are not getting inferred on and then a wrong choice is made on the second or third opportunity. This points to possibly augmenting the data so that more left-sided (late) opportunity windows are seen in training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
